{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().endswith('notebooks'): os.chdir('..')\n",
    "    \n",
    "from random import randint, shuffle\n",
    "from random import random as rand\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import src.tokenization\n",
    "import src.models\n",
    "import src.optim\n",
    "import src.train\n",
    "from src.utils import set_seeds, get_device\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.data import seek_random_offset, SentPairDataset, Pipeline, Preprocess4Pretrain, seq_collate\n",
    "\n",
    "from config import CONFIG as args\n",
    "\n",
    "cfg = src.train.Config.from_json(args.train_cfg)\n",
    "model_cfg = src.models.Config.from_json(args.model_cfg)\n",
    "\n",
    "tokenizer = src.tokenization.FullTokenizer(vocab_file=args.vocab, do_lower_case=True)\n",
    "tokenize = lambda x: tokenizer.tokenize(tokenizer.convert_to_unicode(x))\n",
    "\n",
    "pipeline = [Preprocess4Pretrain(args.max_pred,\n",
    "                                args.mask_prob,\n",
    "                                list(tokenizer.vocab.keys()),\n",
    "                                tokenizer.convert_tokens_to_ids,\n",
    "                                model_cfg.max_len,\n",
    "                                args.mask_alpha,\n",
    "                                args.mask_beta,\n",
    "                                args.max_gram)]\n",
    "data_iter = DataLoader(SentPairDataset(args.data_file,\n",
    "                            cfg.batch_size,\n",
    "                            tokenize,\n",
    "                            model_cfg.max_len,\n",
    "                            pipeline=pipeline), \n",
    "                        batch_size=cfg.batch_size, \n",
    "                        collate_fn=seq_collate,\n",
    "                        num_workers=mp.cpu_count())\n",
    "\n",
    "from src.pretrain import Discriminator\n",
    "# discriminator = Discriminator(model_cfg)\n",
    "\n",
    "from src.pretrain import Generator\n",
    "generator_cfg = src.models.Config.from_json(args.generator_cfg)\n",
    "# generator = Generator(generator_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for batch in tqdm(data_iter):\n",
    "    input_ids, segment_ids, input_mask, masked_ids, masked_pos, masked_weights, is_next, original_ids = batch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_test_senteces: 4358\n",
      "number of outputs per datapoint: 8\n"
     ]
    }
   ],
   "source": [
    "SPD = SentPairDataset('./data/wiki.test.tokens',\n",
    "                        16,\n",
    "                        tokenize,\n",
    "                        400,\n",
    "                        pipeline=pipeline)\n",
    "print(f\"number_of_test_senteces: {len(SPD)}\")\n",
    "one_obs = SPD[0]\n",
    "print(f\"number of outputs per datapoint: {len(one_obs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, input_mask, masked_ids, masked_pos, masked_weights, is_next, original_ids = one_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suspicious feature #1\n",
    "A very suspicious thing over the `input_ids` and `masked_ids`. The `103` seems to appear frequently in `input_ids`, but perhaps, we would have expect it to appear more in `masked_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_id of MASK token: [103]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(101, 101),\n",
       " (102, 102),\n",
       " (2728, 2728),\n",
       " (1026, 1026),\n",
       " (4895, 4895),\n",
       " (2243, 2243),\n",
       " (1028, 1028),\n",
       " (2003, 2003),\n",
       " (2019, 2019),\n",
       " (2394, 2394),\n",
       " (2143, 2143),\n",
       " (103, 1010),\n",
       " (103, 2547),\n",
       " (1998, 1998),\n",
       " (3004, 3004)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"token_id of MASK token: {tokenizer.convert_tokens_to_ids(['[MASK]'])}\\n\")\n",
    "list(zip(input_ids,masked_ids))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [SEP] robert < un ##k > is an english film , television and theatre actor . he had a guest @ - @ starring role on the television series the bill in 2000 . this was followed by a starring role in the play heron ##s written by simon stephens , which was performed in 2001 at the royal court theatre . he had a guest role in the television series judge john [SEP]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.tokenization import convert_ids_to_tokens\n",
    "' '.join([list(tokenizer.vocab)[masked_id] for masked_id in masked_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [SEP] robert < un ##k > is an english film [MASK] [MASK] and theatre actor [MASK] he had a guest [MASK] - @ starring role on the [MASK] series the bill in [MASK] . this was followed by a starring role in the play heron ##s written by simon stephens [MASK] [MASK] [MASK] performed in 2001 at the royal court theatre [MASK] he had a guest role in the television [MASK] judge john [SEP]'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([list(tokenizer.vocab)[masked_id] for masked_id in input_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suspicious feature #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(101, 0),\n",
       " (102, 0),\n",
       " (2728, 1),\n",
       " (1026, 1),\n",
       " (4895, 1),\n",
       " (2243, 1),\n",
       " (1028, 1),\n",
       " (2003, 1)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(input_ids,segment_ids))[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The backward step\n",
    "The backward step has two involved backprop steps in `generator_loss` and `discriminator_loss`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generator loss\n",
    "`(input_ids, segment_ids, input_mask, masked_pos)` -> `model` -> `logits_lm, logits_clsf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pretrain import Generator\n",
    "generator_cfg = src.models.Config.from_json(args.generator_cfg)\n",
    "generator = Generator(generator_cfg)\n",
    "generator.load_state_dict(torch.load(os.path.join('saved', 'generator.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run through the forward step to see it generate the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape: torch.Size([1, 75, 64])\n",
      "\n",
      " running the first hidden state of the CLS token through proj kernel\n",
      "pooled_h.shape: torch.Size([1, 64])\n",
      "\n",
      " masked_pos.shape: torch.Size([1, 75, 64])\n",
      "masked_pos sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " logits_lm.shape: torch.Size([1, 75, 30522])\n",
      "\n",
      " logits_clsf.shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# generating the same \n",
    "input_ids, segment_ids, input_mask, masked_ids, masked_pos, masked_weights, is_next, original_ids = one_obs\n",
    "\n",
    "# transformer hidden states\n",
    "h = generator.transformer(torch.tensor(input_ids).view(1,-1), \n",
    "                          torch.tensor(segment_ids).view(1,-1), \n",
    "                          torch.tensor(input_mask).view(1,-1))\n",
    "print(f\"h.shape: {h.shape}\")\n",
    "\n",
    "# pooled hidden states\n",
    "pooled_h = generator.activ1(generator.fc(h[:, 0]))\n",
    "print(\"\\n running the first hidden state of the CLS token through proj kernel\")\n",
    "print(f\"pooled_h.shape: {pooled_h.shape}\")\n",
    "\n",
    "# Here i honestly hav no fucking idea what hes doing\n",
    "# gather is a like a multi-dim indexing function\n",
    "# but looking at the masked_pos\n",
    "# it looks like nothing happened\n",
    "masked_pos = torch.tensor(masked_pos).view(1,-1)[:, :, None].expand(-1, -1, h.size(-1))\n",
    "h_masked = torch.gather(h, 1, masked_pos)\n",
    "print(f\"\\n masked_pos.shape: {masked_pos.shape}\")\n",
    "print(\"masked_pos sample\")\n",
    "display( masked_pos[:,:5,:5] )\n",
    "h_masked = generator.norm(generator.activ2(generator.linear(h_masked)))\n",
    "\n",
    "# logits of word predictions\n",
    "logits_lm = generator.decoder2(generator.decoder1(h_masked)) + generator.decoder_bias\n",
    "print(f\"\\n logits_lm.shape: {logits_lm.shape}\")\n",
    "\n",
    "# sentence order prediction \n",
    "logits_clsf = generator.classifier(pooled_h)\n",
    "print(f\"\\n logits_clsf.shape: {logits_clsf.shape}\")\n",
    "\n",
    "# calculating the loss\n",
    "cross_ent = nn.CrossEntropyLoss(reduction='none')\n",
    "sent_cross_ent = nn.CrossEntropyLoss()\n",
    "\n",
    "# MLM loss\n",
    "loss_lm = cross_ent(logits_lm.transpose(1, 2), torch.tensor(masked_ids).view(1,-1) ) # for masked LM\n",
    "display( loss_lm.round() )\n",
    "\n",
    "# Sentence order prediction loss\n",
    "loss_sop = sent_cross_ent(logits_clsf, torch.tensor([int(is_next)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_logits = logits_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reaching the discriminator, the author massages the generator output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# in the src, author does this\n",
    "# batch[3] = torch.argmax(generate_logits, dim=2).detach()\n",
    "masked_ids, segment_ids, input_mask, input_ids, _, _, is_next, original_ids = one_obs\n",
    "input_ids = torch.argmax(generate_logits, dim=2).detach()\n",
    "\n",
    "masked_label = (torch.tensor(masked_ids).long() != torch.tensor(original_ids))\n",
    "non_masked_label = torch.tensor(masked_ids) == torch.tensor(original_ids)\n",
    "input_ids[non_masked_label.view(1,-1)] = torch.tensor(original_ids)[non_masked_label]\n",
    "\n",
    "is_replaced = Variable((input_ids.long() != torch.tensor(original_ids).view(1,-1).long()).float())\n",
    "# is_replaced = is_replaced.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the replaced token ids through the discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pretrain import Discriminator\n",
    "discriminator = Discriminator(model_cfg)\n",
    "discriminator.load_state_dict(torch.load(os.path.join('saved', 'discriminator.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# get the token logits\n",
    "h = discriminator.transformer(torch.tensor(input_ids).view(1,-1), \n",
    "                              torch.tensor(segment_ids).view(1,-1), \n",
    "                              torch.tensor(input_mask).view(1,-1) )\n",
    "logits = discriminator.discriminator(h)\n",
    "\n",
    "# Sentence order prediction\n",
    "cls_h = discriminator.activ1(discriminator.fc(h[:, 0]))\n",
    "logits_clsf = discriminator.classifier(cls_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we claculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaced token detection\n",
    "d_bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "logits_lm = logits.squeeze(-1)\n",
    "loss_lm = d_bce_loss(logits_lm, is_replaced) # for masked LM\n",
    "\n",
    "# sentence order prediction\n",
    "loss_lm = loss_lm.mean()\n",
    "loss_sop = sent_cross_ent(logits_clsf, torch.tensor([int(is_next)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Finally, the backward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss\n",
    "ratio = 50\n",
    "d_loss = lm_loss*ratio + nsp_loss\n",
    "\n",
    "# sum of generator and discriminator loss\n",
    "total_loss = g_loss + d_loss \n",
    "loss_sum += total_loss.item() # collates the loss of the whole batch\n",
    "\n",
    "# run the backward step\n",
    "# total_loss.backward()\n",
    "# self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
