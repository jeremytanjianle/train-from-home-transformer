{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electra Training\n",
    "The author uses an `ELECTRA` training object, which seems to contain 3 predominant object classes: `Discriminator`, `Generator`, `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().endswith('notebooks'): os.chdir('..')\n",
    "    \n",
    "from random import randint, shuffle\n",
    "from random import random as rand\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import src.tokenization\n",
    "import src.models\n",
    "import src.optim\n",
    "import src.train\n",
    "from src.utils import set_seeds, get_device\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.data import seek_random_offset, SentPairDataset, Pipeline, Preprocess4Pretrain, seq_collate\n",
    "\n",
    "from config import CONFIG as args\n",
    "\n",
    "cfg = src.train.Config.from_json(args.train_cfg)\n",
    "model_cfg = src.models.Config.from_json(args.model_cfg)\n",
    "\n",
    "tokenizer = src.tokenization.FullTokenizer(vocab_file=args.vocab, do_lower_case=True)\n",
    "tokenize = lambda x: tokenizer.tokenize(tokenizer.convert_to_unicode(x))\n",
    "\n",
    "pipeline = [Preprocess4Pretrain(args.max_pred,\n",
    "                                args.mask_prob,\n",
    "                                list(tokenizer.vocab.keys()),\n",
    "                                tokenizer.convert_tokens_to_ids,\n",
    "                                model_cfg.max_len,\n",
    "                                args.mask_alpha,\n",
    "                                args.mask_beta,\n",
    "                                args.max_gram)]\n",
    "data_iter = DataLoader(SentPairDataset(args.data_file,\n",
    "                            cfg.batch_size,\n",
    "                            tokenize,\n",
    "                            model_cfg.max_len,\n",
    "                            pipeline=pipeline), \n",
    "                        batch_size=cfg.batch_size, \n",
    "                        collate_fn=seq_collate,\n",
    "                        num_workers=mp.cpu_count())\n",
    "\n",
    "from src.pretrain import Discriminator\n",
    "discriminator = Discriminator(model_cfg)\n",
    "\n",
    "from src.pretrain import Generator\n",
    "generator_cfg = src.models.Config.from_json(args.generator_cfg)\n",
    "generator = Generator(generator_cfg)\n",
    "\n",
    "optimizer = src.optim.optim4GPU(cfg, generator, discriminator)\n",
    "# self.g_optimizer = optim.optim4GPU(cfg, generator)\n",
    "trainer = src.train.AdversarialTrainer(cfg, \n",
    "    discriminator, generator, \n",
    "    data_iter, \n",
    "    optimizer, args.ratio, args.save_dir, get_device())\n",
    "os.makedirs(os.path.join(args.log_dir, args.name), exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=os.path.join(args.log_dir, args.name)) # for tensorboardX\n",
    "\n",
    "trainer.train(writer, model_file=None, data_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cfg.save_steps == 10000\n",
    "# trainer.save(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('decoder_bias',\n",
       "              tensor([-0.1247, -0.1097, -0.1262,  ..., -0.0903, -0.1164, -0.1771],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.embed.tok_embed1.weight',\n",
       "              tensor([[ 0.1084, -1.6856,  0.8938,  ..., -1.6080,  0.7902, -0.1269],\n",
       "                      [ 1.4402,  1.1113,  0.3414,  ...,  0.3611,  0.5536, -1.6411],\n",
       "                      [-0.6360, -0.2318, -0.5088,  ..., -1.2780,  0.5024, -0.1618],\n",
       "                      ...,\n",
       "                      [ 0.4303,  1.7491,  0.3746,  ..., -0.1478,  1.0164, -0.0169],\n",
       "                      [-1.6252, -0.2167, -0.8579,  ..., -0.2637, -0.4763,  0.1835],\n",
       "                      [ 1.2073, -0.4374,  0.1862,  ..., -0.1416, -0.1738,  1.2703]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.embed.tok_embed2.weight',\n",
       "              tensor([[ 0.2156,  0.1961,  0.0817,  ...,  0.1595, -0.2192, -0.1461],\n",
       "                      [ 0.0744, -0.0150,  0.1650,  ..., -0.0079,  0.1621, -0.1273],\n",
       "                      [ 0.2460, -0.1386, -0.1071,  ..., -0.0459,  0.1280, -0.1701],\n",
       "                      ...,\n",
       "                      [ 0.0361, -0.1590,  0.1599,  ..., -0.2023, -0.0844,  0.0835],\n",
       "                      [-0.0694, -0.1117,  0.1041,  ...,  0.1950,  0.0884,  0.2561],\n",
       "                      [ 0.0136, -0.2778, -0.0521,  ...,  0.0065, -0.2126,  0.1021]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.embed.tok_embed2.bias',\n",
       "              tensor([ 0.1590, -0.1709, -0.0645,  0.0463, -0.0552,  0.1724, -0.1429, -0.1476,\n",
       "                      -0.1757, -0.0464,  0.0593, -0.1341,  0.0593, -0.1337, -0.0126, -0.1298,\n",
       "                       0.0055, -0.0280,  0.0004,  0.1580, -0.0779, -0.1107, -0.1173,  0.1151,\n",
       "                       0.0329,  0.0801, -0.0361, -0.0403,  0.0236,  0.0245, -0.0036, -0.1003,\n",
       "                       0.0905,  0.0602,  0.1240,  0.0496, -0.0540,  0.1485, -0.0278,  0.1914,\n",
       "                      -0.1691, -0.0592,  0.1415, -0.1237,  0.1731,  0.0839,  0.1646, -0.0607,\n",
       "                      -0.0648, -0.1193, -0.1354, -0.1057, -0.0841,  0.0266,  0.1233,  0.1199,\n",
       "                      -0.0241, -0.1166,  0.1232,  0.0580, -0.1477,  0.0725,  0.0962, -0.0752],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.embed.pos_embed.weight',\n",
       "              tensor([[-1.0333, -0.6855,  0.3829,  ..., -0.2322, -0.7375,  1.3278],\n",
       "                      [ 0.3228,  0.1469,  0.4333,  ...,  0.4176,  1.3111,  0.3686],\n",
       "                      [ 0.6890,  0.9499,  0.9703,  ..., -2.5952,  1.2964,  0.9570],\n",
       "                      ...,\n",
       "                      [-1.0103, -0.7270,  0.6362,  ...,  1.4534, -0.2311,  0.3533],\n",
       "                      [ 1.0009,  0.2029, -0.3933,  ...,  0.5722,  1.6674,  0.9257],\n",
       "                      [ 1.1607,  1.0567,  0.1988,  ...,  0.9381,  0.0038,  0.8581]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.embed.seg_embed.weight',\n",
       "              tensor([[ 6.0362e-01, -1.8115e-01,  9.0136e-01,  6.3357e-01, -7.9380e-01,\n",
       "                       -5.5230e-01,  3.4593e-01,  5.8664e-01, -1.0369e+00, -2.8724e-01,\n",
       "                        2.1444e-01, -1.0969e+00, -5.3611e-01,  4.0846e-01, -1.1126e+00,\n",
       "                        1.1187e+00, -8.7137e-01,  1.3431e+00, -6.0369e-01, -1.0143e+00,\n",
       "                        2.1439e-01, -7.6408e-02, -8.2253e-02, -7.3025e-01,  2.4351e+00,\n",
       "                        1.4932e+00, -1.0818e+00, -3.1060e-01,  3.8418e-01,  6.9262e-01,\n",
       "                       -4.8299e-01, -9.5267e-01, -6.7807e-01,  1.1690e+00, -3.7172e-01,\n",
       "                       -1.8636e+00, -1.1384e+00, -8.3806e-02, -6.4200e-01,  9.5036e-01,\n",
       "                        2.9143e-01, -1.4851e+00, -5.8233e-02, -1.8971e+00,  1.2322e+00,\n",
       "                       -6.0253e-01,  1.1880e-01, -1.0650e+00,  5.9839e-01,  1.0207e+00,\n",
       "                        1.6200e-01,  2.3888e-01,  2.0789e+00, -2.3266e-01, -1.9520e+00,\n",
       "                        3.8477e-01, -3.8617e-01,  2.5301e-01,  1.3581e+00,  1.7751e+00,\n",
       "                       -1.0040e-01, -7.9743e-03,  1.8672e+00,  3.4909e-01],\n",
       "                      [ 1.5888e+00, -1.0292e+00,  3.5345e-01, -6.9325e-01,  2.5513e+00,\n",
       "                        1.2539e-01,  3.4907e-01,  6.1412e-01,  5.7785e-01, -3.7431e-01,\n",
       "                        1.9272e+00,  2.5036e-03, -3.5789e-01, -1.4697e+00, -4.0091e-01,\n",
       "                       -3.9582e-01, -8.8827e-01,  1.4034e+00,  2.1413e-01,  1.0471e+00,\n",
       "                        2.5262e-01, -5.8748e-02,  3.1010e-01,  3.4779e-02, -7.7776e-01,\n",
       "                       -1.1709e+00,  1.0387e+00,  1.1303e-01,  1.6633e+00,  8.9554e-01,\n",
       "                        4.3364e-01,  1.1514e+00,  7.4858e-01,  6.3003e-01, -1.0611e+00,\n",
       "                        2.5599e-01, -8.0851e-01,  5.7857e-02,  1.8501e+00, -1.6364e-01,\n",
       "                       -2.0279e+00, -7.0048e-01,  1.6330e+00, -9.7460e-01, -3.7334e-01,\n",
       "                       -6.3903e-01,  2.1208e+00,  1.7915e+00,  1.2518e+00,  3.2863e-01,\n",
       "                        3.3293e-01, -6.8148e-02,  2.1451e-01,  2.1875e-01, -6.4789e-01,\n",
       "                       -2.1072e-01, -6.4550e-01, -2.4635e-01,  1.5763e-01,  7.7635e-01,\n",
       "                       -2.9063e-01, -5.5180e-02,  4.7461e-01,  1.9475e+00]], device='cuda:0')),\n",
       "             ('transformer.embed.norm.gamma',\n",
       "              tensor([1.0075, 1.0084, 1.0149, 1.0091, 0.9863, 0.9871, 1.0436, 1.0062, 0.9945,\n",
       "                      0.9916, 0.9910, 0.9883, 1.0180, 0.9876, 0.9995, 0.9900, 0.9981, 1.0214,\n",
       "                      0.9980, 0.9863, 1.0610, 1.0336, 0.9823, 1.0079, 0.9942, 0.9793, 1.0024,\n",
       "                      0.9889, 1.0214, 0.9864, 1.0081, 0.9893, 0.9722, 0.9817, 0.9791, 1.0217,\n",
       "                      1.0036, 0.9830, 0.9946, 1.0039, 0.9904, 0.9980, 0.9719, 0.9969, 1.0001,\n",
       "                      0.9983, 0.9940, 1.0056, 0.9910, 1.0033, 0.9887, 1.0399, 1.0054, 1.0309,\n",
       "                      1.0047, 1.0136, 1.0038, 1.0055, 0.9928, 0.9741, 0.9533, 1.0376, 0.9918,\n",
       "                      1.0001], device='cuda:0')),\n",
       "             ('transformer.embed.norm.beta',\n",
       "              tensor([ 8.5250e-04, -1.0896e-02,  7.1172e-03,  3.3187e-03, -6.9006e-03,\n",
       "                       2.7912e-03,  5.7829e-03, -7.5627e-03, -1.0774e-02, -2.7189e-03,\n",
       "                       3.7765e-03, -5.3779e-03, -7.4675e-04, -1.5476e-03,  3.4817e-03,\n",
       "                       7.7340e-03,  2.4355e-04,  9.4103e-04, -2.0362e-03,  1.5238e-02,\n",
       "                      -4.9953e-03, -1.1080e-02,  7.7115e-04,  2.2341e-03,  3.6117e-03,\n",
       "                       1.0040e-02,  7.2172e-03,  8.0112e-04, -6.5503e-03, -4.9580e-03,\n",
       "                      -9.6174e-04,  2.7953e-03,  5.9678e-03, -2.5883e-03,  1.0820e-02,\n",
       "                      -9.7527e-03, -2.2163e-03,  6.8839e-03, -1.0124e-02,  1.4472e-02,\n",
       "                      -4.1365e-03,  2.6332e-03, -8.4917e-03,  4.9328e-04,  8.3430e-03,\n",
       "                       1.6662e-03, -6.5326e-03, -3.9679e-03,  2.2966e-04, -6.0989e-03,\n",
       "                      -1.0226e-02, -2.7694e-05,  6.2989e-03,  1.3986e-03, -6.9385e-03,\n",
       "                      -6.9734e-03,  2.5341e-04, -6.8820e-03,  2.4347e-03,  4.1517e-03,\n",
       "                      -2.8619e-03, -1.0124e-02, -1.3631e-02, -1.3347e-03], device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_q.weight',\n",
       "              tensor([[-0.0255,  0.0107, -0.0456,  ...,  0.0218, -0.0897,  0.0400],\n",
       "                      [-0.0339,  0.0588, -0.0539,  ..., -0.0684,  0.0597,  0.0119],\n",
       "                      [ 0.0485,  0.0936, -0.1009,  ...,  0.0190, -0.0008, -0.0779],\n",
       "                      ...,\n",
       "                      [ 0.0048,  0.1049,  0.0775,  ...,  0.1120,  0.0506, -0.1188],\n",
       "                      [ 0.0462,  0.0316,  0.0930,  ..., -0.0169, -0.0093,  0.0125],\n",
       "                      [ 0.0128, -0.0595,  0.0558,  ...,  0.0640, -0.0266,  0.0515]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_q.bias',\n",
       "              tensor([ 0.0551, -0.0737,  0.0222, -0.0940, -0.1220, -0.0201,  0.0493,  0.0212,\n",
       "                      -0.1063,  0.0838, -0.1043, -0.1393, -0.0550,  0.0560, -0.1238,  0.1353,\n",
       "                       0.0905, -0.1174,  0.1231,  0.0219,  0.1041, -0.0987, -0.0438,  0.0689,\n",
       "                      -0.1210,  0.0652, -0.0700, -0.0223,  0.0637, -0.0480, -0.0938,  0.1120,\n",
       "                       0.0394, -0.0365,  0.0015, -0.0781, -0.0176, -0.0559,  0.0632,  0.0548,\n",
       "                      -0.0754,  0.1200, -0.0894,  0.0819, -0.0858,  0.0414,  0.1033,  0.0403,\n",
       "                      -0.0235, -0.0236,  0.1300,  0.0627, -0.0718,  0.0162,  0.0731,  0.0504,\n",
       "                       0.0312,  0.0511,  0.1123, -0.0394, -0.0780,  0.0172, -0.0420, -0.0142],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_k.weight',\n",
       "              tensor([[ 0.1198, -0.0436, -0.0577,  ...,  0.1237, -0.0440,  0.0734],\n",
       "                      [ 0.1089, -0.0937,  0.0666,  ...,  0.0888, -0.0583,  0.0482],\n",
       "                      [ 0.0412,  0.0117, -0.0132,  ...,  0.1290,  0.0986,  0.0373],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0322, -0.1016,  ...,  0.0170, -0.0489,  0.0992],\n",
       "                      [-0.0153, -0.0326,  0.0576,  ...,  0.1282, -0.0887, -0.0625],\n",
       "                      [ 0.1159,  0.0163, -0.0565,  ...,  0.1417, -0.0793, -0.1178]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_k.bias',\n",
       "              tensor([-0.0005,  0.0978,  0.1007, -0.0100,  0.0956, -0.1095,  0.0792, -0.1231,\n",
       "                      -0.0928,  0.0223, -0.0478, -0.1198, -0.0250,  0.0665, -0.0944, -0.0311,\n",
       "                       0.1058,  0.0202,  0.0067, -0.0902, -0.1216, -0.0391, -0.0146, -0.0054,\n",
       "                       0.0862, -0.0974,  0.0303,  0.0272,  0.0481,  0.0655, -0.0045, -0.0417,\n",
       "                      -0.0601,  0.0485,  0.0166, -0.0093, -0.0059,  0.0410, -0.0011, -0.1043,\n",
       "                      -0.0440, -0.1043, -0.0872, -0.1210,  0.0736, -0.0826,  0.0298, -0.0401,\n",
       "                       0.0772, -0.1107,  0.0400,  0.0863,  0.1070, -0.0620, -0.0587, -0.1187,\n",
       "                       0.0134,  0.0723, -0.1057,  0.0195,  0.0786,  0.0549,  0.0597, -0.0727],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_v.weight',\n",
       "              tensor([[ 0.0288,  0.0208, -0.0696,  ..., -0.0420,  0.0557, -0.0713],\n",
       "                      [ 0.0194, -0.0557, -0.0840,  ..., -0.0933, -0.0079, -0.0883],\n",
       "                      [-0.0831,  0.0867,  0.0116,  ..., -0.0507,  0.0063, -0.0501],\n",
       "                      ...,\n",
       "                      [ 0.0452,  0.0181,  0.0571,  ...,  0.0326,  0.0772,  0.0150],\n",
       "                      [ 0.0780,  0.0903, -0.1248,  ...,  0.0614,  0.1012,  0.0418],\n",
       "                      [-0.0705, -0.0999,  0.0959,  ...,  0.0385,  0.0228,  0.0281]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.attn.proj_v.bias',\n",
       "              tensor([-0.0087, -0.0696,  0.1065, -0.0995,  0.0135,  0.0817, -0.0096, -0.0827,\n",
       "                      -0.0837, -0.0815,  0.0127, -0.0729, -0.0696,  0.0601,  0.1172, -0.1079,\n",
       "                      -0.0093, -0.0518,  0.0553, -0.0659,  0.0365,  0.0394, -0.1135,  0.0858,\n",
       "                      -0.0265, -0.0166,  0.0391,  0.0244,  0.1025,  0.1192, -0.0848,  0.0525,\n",
       "                      -0.0572, -0.1183,  0.0979, -0.1236,  0.0530, -0.1092,  0.1239, -0.0580,\n",
       "                      -0.0749, -0.0676,  0.1118,  0.0467, -0.0423, -0.0017, -0.1103,  0.0352,\n",
       "                       0.0710, -0.0365,  0.0628, -0.0808,  0.0094, -0.0390,  0.0885, -0.0977,\n",
       "                      -0.0236, -0.0842, -0.0351,  0.1101,  0.0064, -0.1035, -0.0743, -0.0610],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.proj.weight',\n",
       "              tensor([[-0.0835,  0.0991,  0.1246,  ..., -0.0848,  0.0223, -0.1366],\n",
       "                      [-0.0728,  0.1088, -0.0499,  ..., -0.0409,  0.0970, -0.0435],\n",
       "                      [-0.0450, -0.0108, -0.0304,  ...,  0.0948,  0.0315,  0.0466],\n",
       "                      ...,\n",
       "                      [ 0.0819,  0.0558,  0.0558,  ...,  0.0070,  0.0079, -0.0094],\n",
       "                      [-0.0273,  0.0848, -0.0396,  ..., -0.0859, -0.0252, -0.1092],\n",
       "                      [ 0.0208,  0.0320, -0.0194,  ..., -0.1175, -0.0188,  0.0121]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.proj.bias',\n",
       "              tensor([ 0.0943,  0.0043,  0.0241, -0.0990,  0.1217, -0.0739, -0.0369,  0.0856,\n",
       "                      -0.0130, -0.0302, -0.0434,  0.1252,  0.1155,  0.0125, -0.0389,  0.1091,\n",
       "                      -0.0350,  0.0777,  0.0374,  0.0078, -0.1125,  0.0138,  0.0941,  0.0755,\n",
       "                      -0.0356,  0.0844,  0.0405,  0.0096, -0.1149,  0.0418, -0.0797, -0.0344,\n",
       "                       0.0708, -0.0630, -0.0205, -0.0539,  0.0463,  0.0153, -0.1080,  0.0409,\n",
       "                       0.1035,  0.0962, -0.0428, -0.0921, -0.0401,  0.0785, -0.1113, -0.0372,\n",
       "                      -0.0894,  0.0656,  0.0681, -0.1002, -0.0071, -0.0256, -0.0275,  0.0800,\n",
       "                       0.0788,  0.0442,  0.0092,  0.0390, -0.0554, -0.0360,  0.0542,  0.0322],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.norm1.gamma',\n",
       "              tensor([1.0046, 1.0046, 0.9933, 1.0009, 0.9918, 0.9914, 1.0070, 1.0055, 0.9977,\n",
       "                      1.0000, 0.9823, 0.9837, 1.0038, 0.9965, 0.9970, 0.9915, 0.9937, 0.9963,\n",
       "                      0.9992, 0.9991, 0.9923, 1.0125, 0.9981, 0.9961, 0.9978, 0.9937, 0.9928,\n",
       "                      0.9944, 0.9983, 0.9906, 0.9957, 1.0004, 1.0021, 0.9879, 0.9882, 1.0036,\n",
       "                      1.0018, 0.9908, 0.9929, 0.9923, 0.9774, 0.9979, 0.9973, 1.0016, 0.9927,\n",
       "                      0.9924, 0.9923, 1.0034, 0.9987, 0.9944, 0.9950, 0.9986, 1.0009, 1.0000,\n",
       "                      0.9948, 0.9953, 0.9742, 0.9928, 0.9981, 0.9899, 0.9868, 0.9942, 0.9873,\n",
       "                      1.0021], device='cuda:0')),\n",
       "             ('transformer.block.norm1.beta',\n",
       "              tensor([ 3.6561e-03, -8.0650e-04, -2.5685e-04,  2.1240e-03,  1.1032e-02,\n",
       "                      -5.6308e-03,  9.3304e-03, -1.3891e-02, -6.3771e-03, -2.8255e-03,\n",
       "                      -4.7099e-03, -2.4662e-03, -4.1554e-03,  7.4388e-03,  2.0560e-03,\n",
       "                       3.9113e-03, -1.3524e-04,  2.5564e-03, -8.6635e-03,  3.0195e-03,\n",
       "                       4.8137e-04, -2.8237e-03,  7.0798e-03,  6.6325e-03,  7.0092e-03,\n",
       "                       9.1092e-03,  1.2843e-04,  8.1204e-03, -1.3795e-03, -1.4079e-04,\n",
       "                      -1.2543e-03,  1.1069e-03,  8.8717e-03,  4.6001e-03, -6.7439e-04,\n",
       "                      -1.0336e-02, -7.6082e-05,  5.0460e-03, -1.4012e-03,  4.0441e-03,\n",
       "                       5.0448e-03,  1.6776e-02,  8.2262e-04, -8.7397e-03,  2.6442e-03,\n",
       "                      -1.3900e-04, -8.6667e-03, -9.3353e-03, -7.7476e-03, -1.4724e-03,\n",
       "                      -6.0749e-03, -1.7024e-03,  1.0594e-03,  6.5958e-03, -2.9985e-03,\n",
       "                      -4.1214e-03,  3.3692e-03, -6.3864e-03, -9.3194e-04,  8.6487e-03,\n",
       "                       1.5343e-04, -1.9984e-03, -9.0531e-03,  3.8171e-03], device='cuda:0')),\n",
       "             ('transformer.block.pwff.fc1.weight',\n",
       "              tensor([[-0.1021, -0.0959,  0.0490,  ...,  0.0485,  0.0960,  0.1106],\n",
       "                      [-0.0987,  0.0563, -0.0345,  ...,  0.0692, -0.0623,  0.0283],\n",
       "                      [-0.0053,  0.0747, -0.0459,  ..., -0.0634,  0.0920, -0.0261],\n",
       "                      ...,\n",
       "                      [-0.1027,  0.0081, -0.1008,  ..., -0.0404,  0.0494,  0.0547],\n",
       "                      [ 0.0916,  0.0076,  0.0121,  ..., -0.0033, -0.0072,  0.0458],\n",
       "                      [ 0.1021,  0.0584,  0.0394,  ..., -0.0447,  0.0011, -0.0616]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.pwff.fc1.bias',\n",
       "              tensor([ 0.1149,  0.0351, -0.0166,  0.0836, -0.0997, -0.0173,  0.0123,  0.1134,\n",
       "                      -0.0642,  0.0332, -0.0328, -0.0828, -0.0955,  0.0977, -0.0561, -0.0216,\n",
       "                      -0.0065,  0.1195,  0.0625,  0.0050,  0.0637,  0.0926, -0.0451,  0.0859,\n",
       "                       0.0249,  0.1065,  0.0412, -0.0793,  0.0390,  0.1186,  0.0002, -0.0917,\n",
       "                       0.0887, -0.0927,  0.0976,  0.0883,  0.0340, -0.0806,  0.0668,  0.0497,\n",
       "                       0.0108, -0.0211,  0.1227, -0.0839,  0.0301, -0.0369, -0.0342, -0.0156,\n",
       "                       0.0005, -0.0075,  0.0405, -0.0239,  0.0115,  0.0507,  0.0227,  0.0144,\n",
       "                       0.0216,  0.0029,  0.0644, -0.0608,  0.0449,  0.0264,  0.0126,  0.1084,\n",
       "                       0.1245, -0.0064,  0.0879, -0.0507,  0.0157, -0.0378, -0.1078, -0.0296,\n",
       "                      -0.0996, -0.0802,  0.1174,  0.0758,  0.0569,  0.0777, -0.0379, -0.1124,\n",
       "                       0.0297,  0.0742, -0.0619,  0.0358, -0.0461, -0.0115,  0.0505,  0.0264,\n",
       "                       0.0299, -0.1166,  0.0912, -0.0997,  0.0009, -0.0845,  0.1215, -0.0590,\n",
       "                      -0.0954,  0.0206,  0.0725, -0.1227,  0.0661,  0.0849,  0.0156, -0.0780,\n",
       "                      -0.1032,  0.0476,  0.1021, -0.1074, -0.0456,  0.0204,  0.0176,  0.1018,\n",
       "                      -0.0151, -0.0656, -0.0310, -0.1054, -0.0849,  0.0099, -0.0626, -0.0632,\n",
       "                      -0.1060, -0.0178,  0.0483,  0.0337, -0.0642, -0.1052, -0.1076, -0.0431,\n",
       "                       0.0039, -0.0040, -0.0367,  0.0922,  0.0407,  0.1017, -0.0030,  0.0157,\n",
       "                       0.0181, -0.0594,  0.0661, -0.0385, -0.0512, -0.0770, -0.0886, -0.0491,\n",
       "                       0.0702,  0.1104, -0.0214, -0.0373, -0.1177, -0.0990,  0.0204, -0.0147,\n",
       "                      -0.1054,  0.0889,  0.1155,  0.0586, -0.0701, -0.0949,  0.0065,  0.0846,\n",
       "                       0.1143,  0.0746,  0.0344, -0.0072,  0.0364, -0.0821, -0.0502, -0.0037,\n",
       "                       0.0060,  0.0743,  0.0834,  0.1110, -0.0455,  0.0278, -0.0478, -0.0680,\n",
       "                       0.1169,  0.0568,  0.1121,  0.0533, -0.1025,  0.0131,  0.0567,  0.0562,\n",
       "                       0.0490,  0.0225, -0.1131,  0.0579,  0.0149, -0.0801, -0.0260,  0.0663,\n",
       "                      -0.0372, -0.0201, -0.0010,  0.0834, -0.0005, -0.0276, -0.0874, -0.0297,\n",
       "                       0.0682,  0.0288,  0.0877, -0.0683, -0.0293, -0.1120, -0.0850, -0.0396,\n",
       "                       0.0610, -0.0324, -0.1224, -0.0133,  0.0633, -0.0930,  0.0734, -0.0571,\n",
       "                      -0.0782, -0.0019, -0.0064, -0.0708,  0.0750,  0.0697, -0.0560, -0.0029,\n",
       "                      -0.0914, -0.0134,  0.0653,  0.0932,  0.1093,  0.0142,  0.1199,  0.0574,\n",
       "                      -0.0004, -0.0743, -0.0476,  0.0646,  0.0927, -0.0415,  0.0607,  0.0358,\n",
       "                      -0.0621, -0.0239, -0.0904, -0.0572, -0.0737,  0.0328, -0.0451, -0.0348,\n",
       "                      -0.0571, -0.0650, -0.0496,  0.0366, -0.0769, -0.0794, -0.1074, -0.0522],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.pwff.fc2.weight',\n",
       "              tensor([[-0.0572, -0.0425,  0.0407,  ..., -0.0265, -0.0231,  0.0291],\n",
       "                      [ 0.0110, -0.0235, -0.0072,  ...,  0.0143, -0.0106,  0.0202],\n",
       "                      [-0.0309, -0.0124, -0.0072,  ...,  0.0161,  0.0217,  0.0558],\n",
       "                      ...,\n",
       "                      [-0.0188, -0.0150, -0.0298,  ..., -0.0572, -0.0352,  0.0211],\n",
       "                      [ 0.0344, -0.0138,  0.0223,  ..., -0.0546,  0.0412,  0.0363],\n",
       "                      [ 0.0249, -0.0259, -0.0512,  ..., -0.0529, -0.0026, -0.0294]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.pwff.fc2.bias',\n",
       "              tensor([ 0.0418, -0.0396,  0.0210, -0.0215,  0.0324,  0.0375,  0.0620,  0.0211,\n",
       "                      -0.0310,  0.0094, -0.0257,  0.0300,  0.0322, -0.0243,  0.0185, -0.0034,\n",
       "                       0.0461,  0.0390,  0.0027,  0.0458, -0.0228,  0.0215,  0.0058, -0.0137,\n",
       "                       0.0560, -0.0199, -0.0265,  0.0280, -0.0215, -0.0346,  0.0089, -0.0004,\n",
       "                      -0.0318,  0.0156, -0.0365,  0.0439, -0.0104, -0.0573,  0.0385,  0.0300,\n",
       "                       0.0226, -0.0536,  0.0291,  0.0478,  0.0452,  0.0133, -0.0387,  0.0176,\n",
       "                       0.0104, -0.0348, -0.0298,  0.0270,  0.0118, -0.0476,  0.0300, -0.0079,\n",
       "                       0.0037, -0.0417,  0.0216,  0.0494, -0.0326, -0.0043, -0.0097,  0.0465],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.block.norm2.gamma',\n",
       "              tensor([1.0037, 1.0032, 0.9931, 0.9986, 0.9943, 0.9978, 1.0065, 1.0068, 1.0006,\n",
       "                      1.0043, 0.9848, 0.9899, 1.0025, 0.9965, 0.9968, 0.9935, 0.9942, 0.9966,\n",
       "                      1.0014, 1.0007, 0.9882, 1.0189, 1.0035, 0.9975, 1.0014, 0.9936, 0.9959,\n",
       "                      1.0002, 0.9974, 0.9928, 0.9977, 1.0066, 1.0053, 0.9901, 0.9951, 1.0055,\n",
       "                      1.0039, 0.9943, 0.9954, 0.9934, 0.9825, 1.0013, 1.0049, 1.0022, 0.9965,\n",
       "                      0.9961, 0.9967, 1.0049, 1.0057, 0.9940, 0.9998, 0.9995, 1.0023, 1.0002,\n",
       "                      0.9958, 0.9962, 0.9757, 0.9943, 1.0018, 0.9944, 0.9942, 0.9944, 0.9898,\n",
       "                      1.0052], device='cuda:0')),\n",
       "             ('transformer.block.norm2.beta',\n",
       "              tensor([ 0.0045, -0.0005,  0.0008,  0.0017,  0.0122, -0.0074,  0.0110, -0.0152,\n",
       "                      -0.0059, -0.0021, -0.0042, -0.0035, -0.0051,  0.0083,  0.0011,  0.0049,\n",
       "                      -0.0006,  0.0020, -0.0091,  0.0016,  0.0008, -0.0015,  0.0079,  0.0068,\n",
       "                       0.0075,  0.0068, -0.0001,  0.0088,  0.0003, -0.0006,  0.0001,  0.0001,\n",
       "                       0.0097,  0.0049, -0.0025, -0.0118, -0.0006,  0.0039, -0.0019,  0.0046,\n",
       "                       0.0063,  0.0164,  0.0013, -0.0097,  0.0028, -0.0006, -0.0087, -0.0092,\n",
       "                      -0.0090, -0.0013, -0.0079, -0.0017,  0.0010,  0.0049, -0.0026, -0.0046,\n",
       "                       0.0034, -0.0062, -0.0011,  0.0085, -0.0009, -0.0018, -0.0088,  0.0043],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 0.0417,  0.0110,  0.0726,  ..., -0.0081,  0.0907, -0.0867],\n",
       "                      [-0.0032, -0.0839,  0.0572,  ...,  0.0070, -0.1029,  0.0765],\n",
       "                      [ 0.0557,  0.1123, -0.0438,  ...,  0.0144, -0.0408, -0.0473],\n",
       "                      ...,\n",
       "                      [-0.0869, -0.0251,  0.0725,  ..., -0.0611, -0.0941,  0.0820],\n",
       "                      [-0.0058, -0.0522,  0.0262,  ..., -0.0459, -0.0655, -0.1142],\n",
       "                      [-0.0955, -0.1042, -0.0238,  ...,  0.1202,  0.0925, -0.0701]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([-0.0316,  0.0625,  0.0833,  0.0779,  0.0917, -0.0924, -0.0938, -0.0318,\n",
       "                      -0.0533, -0.0098, -0.0633, -0.0696,  0.1248,  0.0759, -0.0299, -0.0390,\n",
       "                       0.0992,  0.0456,  0.0815,  0.0736,  0.0169, -0.0114, -0.1188,  0.0396,\n",
       "                       0.0440,  0.0432, -0.0442, -0.0659, -0.0688, -0.0244, -0.0053,  0.0455,\n",
       "                       0.0833,  0.0600, -0.0467,  0.0718, -0.0012, -0.0538, -0.0844,  0.0686,\n",
       "                       0.1288,  0.0763, -0.0269,  0.0640,  0.0670, -0.0642, -0.1011, -0.0775,\n",
       "                      -0.0750, -0.0744,  0.0927, -0.0874, -0.0986, -0.0433,  0.0679, -0.0731,\n",
       "                      -0.0049, -0.0855,  0.0391, -0.0110, -0.0661,  0.1018,  0.0439,  0.0179],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.weight',\n",
       "              tensor([[-0.0784, -0.0321,  0.0170,  ..., -0.0069, -0.0856, -0.0561],\n",
       "                      [ 0.0819, -0.0263,  0.0986,  ...,  0.1360,  0.0900, -0.0037],\n",
       "                      [ 0.0047,  0.0427,  0.0013,  ..., -0.0682, -0.1069, -0.0169],\n",
       "                      ...,\n",
       "                      [ 0.0101,  0.0689, -0.0464,  ...,  0.0612,  0.0841, -0.0097],\n",
       "                      [ 0.1156,  0.0672,  0.0157,  ..., -0.0307, -0.0646,  0.0456],\n",
       "                      [ 0.0780, -0.1145, -0.0980,  ..., -0.1502,  0.0422,  0.1006]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.1023, -0.0839, -0.0022,  0.0841,  0.1022,  0.0651,  0.1015, -0.1070,\n",
       "                       0.0810,  0.1203,  0.1215, -0.0417,  0.0727, -0.0246,  0.1108,  0.0167,\n",
       "                       0.1018,  0.0320, -0.0275,  0.0336, -0.0050,  0.0130,  0.1175,  0.0931,\n",
       "                      -0.0453,  0.1208, -0.0987,  0.0759,  0.0154,  0.0297,  0.1169,  0.0662,\n",
       "                      -0.1084, -0.0693,  0.0853, -0.0632, -0.0267,  0.0732, -0.0106, -0.0625,\n",
       "                       0.1013, -0.0140, -0.0428,  0.0181,  0.1189,  0.0665, -0.0769, -0.0675,\n",
       "                      -0.0777,  0.0416,  0.1306,  0.0029, -0.0501,  0.1227,  0.0308,  0.1057,\n",
       "                      -0.1112,  0.0621, -0.1135,  0.0526,  0.0494,  0.1105,  0.0959, -0.0321],\n",
       "                     device='cuda:0')),\n",
       "             ('norm.gamma',\n",
       "              tensor([1.0496, 1.0239, 1.0490, 1.0058, 1.0624, 1.0224, 1.0283, 1.0491, 1.0367,\n",
       "                      1.0709, 1.0447, 1.0595, 1.0412, 1.0388, 1.0485, 1.0386, 1.0532, 1.0636,\n",
       "                      0.9959, 1.0207, 1.0796, 1.0499, 0.9908, 1.0207, 0.9895, 0.9978, 1.0279,\n",
       "                      1.0098, 0.9956, 1.0749, 1.0474, 1.0159, 0.9980, 1.0577, 1.0443, 0.9831,\n",
       "                      1.0557, 1.0710, 1.0262, 1.0457, 1.0316, 1.0238, 1.0298, 1.0091, 1.0136,\n",
       "                      1.0625, 1.0565, 1.0391, 1.0146, 0.9920, 1.0472, 0.9906, 1.0296, 0.9985,\n",
       "                      1.0537, 1.0143, 0.9939, 1.0324, 0.9858, 1.0003, 1.0569, 1.0611, 0.9996,\n",
       "                      1.0113], device='cuda:0')),\n",
       "             ('norm.beta',\n",
       "              tensor([ 0.0066,  0.0008, -0.0022,  0.0070,  0.0147, -0.0059,  0.0015,  0.0005,\n",
       "                      -0.0079,  0.0059,  0.0032, -0.0098, -0.0116,  0.0026, -0.0033, -0.0155,\n",
       "                      -0.0189,  0.0096,  0.0055, -0.0095, -0.0034, -0.0053,  0.0083, -0.0205,\n",
       "                       0.0118, -0.0112,  0.0091,  0.0040,  0.0094, -0.0052, -0.0066, -0.0011,\n",
       "                       0.0012, -0.0031, -0.0083,  0.0036,  0.0166,  0.0078,  0.0044, -0.0056,\n",
       "                       0.0077, -0.0055,  0.0060, -0.0029, -0.0076, -0.0098,  0.0011,  0.0056,\n",
       "                       0.0041,  0.0009,  0.0066,  0.0030, -0.0125,  0.0018,  0.0033,  0.0039,\n",
       "                       0.0069,  0.0032,  0.0130, -0.0118, -0.0225, -0.0032, -0.0037, -0.0034],\n",
       "                     device='cuda:0')),\n",
       "             ('classifier.weight',\n",
       "              tensor([[-0.0463,  0.0592, -0.1068,  0.1343,  0.0352,  0.0573,  0.1007,  0.0672,\n",
       "                       -0.0993, -0.0014, -0.0885,  0.0966, -0.1399,  0.0194, -0.0881,  0.0044,\n",
       "                        0.0416, -0.1214,  0.1189, -0.0459, -0.1261, -0.1234,  0.0986, -0.1239,\n",
       "                        0.1125, -0.0396,  0.0565, -0.1324,  0.0720, -0.0396, -0.1124, -0.1342,\n",
       "                        0.0384, -0.0931, -0.0759, -0.0770,  0.0875, -0.0221,  0.0120, -0.0701,\n",
       "                        0.0089,  0.0013,  0.0281,  0.0517, -0.1038, -0.1041,  0.0213, -0.0245,\n",
       "                        0.0878, -0.1324,  0.1184, -0.0661, -0.0703,  0.1229, -0.1111,  0.1197,\n",
       "                       -0.1017,  0.0371, -0.1091,  0.1189, -0.0579,  0.0207, -0.0590,  0.0425],\n",
       "                      [ 0.1208, -0.0969,  0.0391,  0.0682,  0.0742, -0.1149,  0.0463,  0.0935,\n",
       "                        0.0049, -0.1016,  0.0134,  0.0248,  0.1458,  0.0895,  0.1399, -0.1086,\n",
       "                       -0.0788,  0.0682, -0.0843, -0.0134,  0.0737,  0.1385,  0.0149, -0.0599,\n",
       "                        0.0956, -0.0453, -0.0378,  0.0389, -0.0373,  0.0812,  0.0145,  0.0931,\n",
       "                       -0.0431,  0.0382,  0.1398,  0.0073,  0.0183, -0.0869, -0.0318,  0.0170,\n",
       "                        0.0292, -0.0684,  0.1169, -0.0477, -0.1215, -0.0990,  0.1001, -0.0475,\n",
       "                       -0.0712,  0.0857,  0.0006,  0.1141,  0.1129,  0.0033,  0.1067, -0.1233,\n",
       "                       -0.0184,  0.0962, -0.0050,  0.0521,  0.1075, -0.0858,  0.0963, -0.0454]],\n",
       "                     device='cuda:0')),\n",
       "             ('classifier.bias', tensor([-0.1001, -0.0052], device='cuda:0')),\n",
       "             ('decoder1.weight',\n",
       "              tensor([[ 0.1765,  0.0562,  0.1866,  ...,  0.0355,  0.0316,  0.0587],\n",
       "                      [ 0.1824, -0.0720, -0.0756,  ..., -0.0920, -0.0616, -0.1783],\n",
       "                      [ 0.0298,  0.1416,  0.0233,  ...,  0.1167,  0.0545, -0.0866],\n",
       "                      ...,\n",
       "                      [ 0.1169,  0.0685, -0.0249,  ..., -0.1726,  0.1262,  0.0021],\n",
       "                      [-0.1752,  0.1340,  0.0867,  ..., -0.0339,  0.1658, -0.1974],\n",
       "                      [-0.0926, -0.0368, -0.1199,  ...,  0.1648,  0.1651,  0.0681]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder2.weight',\n",
       "              tensor([[ 0.1084, -1.6856,  0.8938,  ..., -1.6080,  0.7902, -0.1269],\n",
       "                      [ 1.4402,  1.1113,  0.3414,  ...,  0.3611,  0.5536, -1.6411],\n",
       "                      [-0.6360, -0.2318, -0.5088,  ..., -1.2780,  0.5024, -0.1618],\n",
       "                      ...,\n",
       "                      [ 0.4303,  1.7491,  0.3746,  ..., -0.1478,  1.0164, -0.0169],\n",
       "                      [-1.6252, -0.2167, -0.8579,  ..., -0.2637, -0.4763,  0.1835],\n",
       "                      [ 1.2073, -0.4374,  0.1862,  ..., -0.1416, -0.1738,  1.2703]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.generator.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite frankly, the saving and loading is shit. Propose a saving and loading of `state_dict` with the following code snippet.  \n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html  \n",
    "\n",
    "```\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().endswith('notebooks'): os.chdir('..')\n",
    "    \n",
    "from random import randint, shuffle\n",
    "from random import random as rand\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import src.tokenization\n",
    "import src.models\n",
    "import src.optim\n",
    "import src.train\n",
    "from src.utils import set_seeds, get_device\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.data import seek_random_offset, SentPairDataset, Pipeline, Preprocess4Pretrain, seq_collate\n",
    "\n",
    "from config import CONFIG as args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Tokenizer and pipelines\n",
    "There is a curious 2 parameters `max_len` in the `electra.json` and `max_pred` in the `config.py`.  \n",
    "`max_len` is the maximum sequence of our model whereas `max_pred` is intended for the training class, the maximum number of replaced tokens. But what is alarming is that the `DataLoader` consistently raises errors when the two are different. Meaning they are intended to be different numbers, but for some reason they are enforced to be the same in the data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(seed=128, batch_size=10, lr=0.0005, n_epochs=10, warmup=0.1, save_steps=10000, total_steps=1000000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = src.train.Config.from_json(args.train_cfg)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(vocab_size=30522, hidden=256, hidden_ff=1024, embedding=64, p_drop_hidden=0.1, n_layers=12, n_heads=4, max_len=400, n_segments=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = src.models.Config.from_json(args.model_cfg)\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = src.tokenization.FullTokenizer(vocab_file=args.vocab, do_lower_case=True)\n",
    "tokenize = lambda x: tokenizer.tokenize(tokenizer.convert_to_unicode(x))\n",
    "\n",
    "pipeline = [Preprocess4Pretrain(args.max_pred,\n",
    "                                args.mask_prob,\n",
    "                                list(tokenizer.vocab.keys()),\n",
    "                                tokenizer.convert_tokens_to_ids,\n",
    "                                model_cfg.max_len,\n",
    "                                args.mask_alpha,\n",
    "                                args.mask_beta,\n",
    "                                args.max_gram)]\n",
    "data_iter = DataLoader(SentPairDataset(args.data_file,\n",
    "                            cfg.batch_size,\n",
    "                            tokenize,\n",
    "                            model_cfg.max_len,\n",
    "                            pipeline=pipeline), \n",
    "                        batch_size=cfg.batch_size, \n",
    "                        collate_fn=seq_collate,\n",
    "                        num_workers=mp.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/wiki.train.tokens'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pretrain import Discriminator\n",
    "discriminator = Discriminator(model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(vocab_size=30522, hidden=64, hidden_ff=256, embedding=32, p_drop_hidden=0.1, n_layers=12, n_heads=1, max_len=400, n_segments=2)\n"
     ]
    }
   ],
   "source": [
    "from src.pretrain import Generator\n",
    "generator_cfg = src.models.Config.from_json(args.generator_cfg)\n",
    "generator = Generator(generator_cfg)\n",
    "print(generator_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. AdversarialTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda (1 GPUs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = src.optim.optim4GPU(cfg, generator, discriminator)\n",
    "# self.g_optimizer = optim.optim4GPU(cfg, generator)\n",
    "trainer = src.train.AdversarialTrainer(cfg, \n",
    "    discriminator, generator, \n",
    "    data_iter, \n",
    "    optimizer, args.ratio, args.save_dir, get_device())\n",
    "os.makedirs(os.path.join(args.log_dir, args.name), exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=os.path.join(args.log_dir, args.name)) # for tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iter (loss=X.XXX):   0%|          | 0/3672 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 109, in __getitem__\n    instance = proc(instance)\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 192, in __call__\n    assert len(v) == self.max_len, f\"unexpected shape in {k}: {v}\"\nAssertionError: unexpected shape in masked_ids: [101, 12411, 5558, 2053, 11748, 4801, 4360, 1017, 1024, 1026, 4895, 2243, 1028, 11906, 1006, 2887, 1024, 1856, 30332, 30197, 30222, 30218, 30259, 30227, 30255, 30258, 30219, 2509, 1010, 5507, 1012, 11748, 4801, 4360, 1997, 1996, 11686, 1017, 1007, 1010, 4141, 3615, 2000, 2004, 11748, 4801, 4360, 11906, 3523, 2648, 2900, 1010, 2003, 1037, 8608, 2535, 1030, 1011, 1030, 2652, 2678, 2208, 2764, 2011, 16562, 1998, 2865, 1012, 4432, 2005, 1996, 9160, 12109, 1012, 2207, 1999, 2254, 2249, 1999, 2900, 1010, 2009, 2003, 1996, 2353, 2208, 1999, 1996, 11748, 4801, 4360, 2186, 1012, 1026, 4895, 2243, 1028, 1996, 2168, 10077, 1997, 8608, 1998, 2613, 1030, 1011, 1030, 2051, 11247, 2004, 2049, 16372, 1010, 1996, 2466, 3216, 5903, 2000, 1996, 2034, 2208, 1998, 4076, 1996, 1000, 2171, 3238, 1000, 1010, 1037, 18476, 2510, 3131, 3529, 1996, 3842, 1997, 26033, 2401, 2076, 1996, 2117, 12124, 2078, 2162, 2040, 4685, 3595, 2304, 3136, 1998, 2024, 25895, 2114, 1996, 4461, 3131, 1000, 1026, 4895, 2243, 1028, 10000, 1000, 1012, 1996, 2208, 2211, 2458, 1999, 2230, 1010, 4755, 2058, 1037, 2312, 4664, 1997, 1996, 2147, 2589, 2006, 11748, 4801, 4360, 11906, 2462, 1012, 2096, 2009, 6025, 1996, 3115, 2838, 1997, 1996, 2186, 1010, 2009, 2036, 9601, 3674, 24081, 1010, 2107, 2004, 2437, 1996, 2208, 2062, 1026, 4895, 2243, 1028, 2005, 2186, 24159, 1012, 2839, 5859, 1026, 4895, 2243, 1028, 10189, 23099, 1998, 4543, 2718, 24303, 7842, 21138, 11439, 2119, 2513, 2013, 3025, 10445, 1010, 2247, 2007, 11748, 4801, 4360, 11906, 2462, 2472, 3138, 4048, 11472, 10830, 1012, 1037, 2312, 2136, 1997, 4898, 8971, 1996, 5896, 1012, 1996, 2208, 1005, 1055, 3098, 4323, 2001, 7042, 2011, 2089, 1005, 1050, 1012, 102, 2009, 2777, 2007, 3893, 4341, 1999, 2900, 1010, 1998, 2001, 5868, 2011, 2119, 2887, 1998, 2530, 4401, 1012, 2044, 2713, 1010, 2009, 2363, 26720, 4180, 1010, 2247, 2007, 2019, 4423, 3179, 1999, 2281, 1997, 2008, 2095, 1012, 2009, 2001, 2036, 5967, 2046, 8952, 1998, 2019, 2434, 2678, 7284, 2186, 1012, 2349, 2000, 2659, 4341, 1997, 11748, 4801, 4360, 11906, 2462, 1010, 11748, 4801, 4360, 11906, 3523, 2001, 2025, 22574, 1010, 2021, 1037, 5470, 5449, 11892, 2007, 1996, 2208, 1005, 1055, 4423, 3179, 2001, 2207, 1999, 2297, 1012, 2865, 1012, 4432, 2052, 2709, 2000, 1996, 6329, 2007, 1996, 2458, 1997, 11748, 4801, 4360, 1024, 24296, 4329, 2005, 1996, 9160, 1018, 1012, 102]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b45e166bb71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_parallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/trainfromhome-transformer/src/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, writer, model_file, data_parallel)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;31m# the sum of iteration losses to get average loss in every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0miter_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Iter (loss=X.XXX)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 109, in __getitem__\n    instance = proc(instance)\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 192, in __call__\n    assert len(v) == self.max_len, f\"unexpected shape in {k}: {v}\"\nAssertionError: unexpected shape in masked_ids: [101, 12411, 5558, 2053, 11748, 4801, 4360, 1017, 1024, 1026, 4895, 2243, 1028, 11906, 1006, 2887, 1024, 1856, 30332, 30197, 30222, 30218, 30259, 30227, 30255, 30258, 30219, 2509, 1010, 5507, 1012, 11748, 4801, 4360, 1997, 1996, 11686, 1017, 1007, 1010, 4141, 3615, 2000, 2004, 11748, 4801, 4360, 11906, 3523, 2648, 2900, 1010, 2003, 1037, 8608, 2535, 1030, 1011, 1030, 2652, 2678, 2208, 2764, 2011, 16562, 1998, 2865, 1012, 4432, 2005, 1996, 9160, 12109, 1012, 2207, 1999, 2254, 2249, 1999, 2900, 1010, 2009, 2003, 1996, 2353, 2208, 1999, 1996, 11748, 4801, 4360, 2186, 1012, 1026, 4895, 2243, 1028, 1996, 2168, 10077, 1997, 8608, 1998, 2613, 1030, 1011, 1030, 2051, 11247, 2004, 2049, 16372, 1010, 1996, 2466, 3216, 5903, 2000, 1996, 2034, 2208, 1998, 4076, 1996, 1000, 2171, 3238, 1000, 1010, 1037, 18476, 2510, 3131, 3529, 1996, 3842, 1997, 26033, 2401, 2076, 1996, 2117, 12124, 2078, 2162, 2040, 4685, 3595, 2304, 3136, 1998, 2024, 25895, 2114, 1996, 4461, 3131, 1000, 1026, 4895, 2243, 1028, 10000, 1000, 1012, 1996, 2208, 2211, 2458, 1999, 2230, 1010, 4755, 2058, 1037, 2312, 4664, 1997, 1996, 2147, 2589, 2006, 11748, 4801, 4360, 11906, 2462, 1012, 2096, 2009, 6025, 1996, 3115, 2838, 1997, 1996, 2186, 1010, 2009, 2036, 9601, 3674, 24081, 1010, 2107, 2004, 2437, 1996, 2208, 2062, 1026, 4895, 2243, 1028, 2005, 2186, 24159, 1012, 2839, 5859, 1026, 4895, 2243, 1028, 10189, 23099, 1998, 4543, 2718, 24303, 7842, 21138, 11439, 2119, 2513, 2013, 3025, 10445, 1010, 2247, 2007, 11748, 4801, 4360, 11906, 2462, 2472, 3138, 4048, 11472, 10830, 1012, 1037, 2312, 2136, 1997, 4898, 8971, 1996, 5896, 1012, 1996, 2208, 1005, 1055, 3098, 4323, 2001, 7042, 2011, 2089, 1005, 1050, 1012, 102, 2009, 2777, 2007, 3893, 4341, 1999, 2900, 1010, 1998, 2001, 5868, 2011, 2119, 2887, 1998, 2530, 4401, 1012, 2044, 2713, 1010, 2009, 2363, 26720, 4180, 1010, 2247, 2007, 2019, 4423, 3179, 1999, 2281, 1997, 2008, 2095, 1012, 2009, 2001, 2036, 5967, 2046, 8952, 1998, 2019, 2434, 2678, 7284, 2186, 1012, 2349, 2000, 2659, 4341, 1997, 11748, 4801, 4360, 11906, 2462, 1010, 11748, 4801, 4360, 11906, 3523, 2001, 2025, 22574, 1010, 2021, 1037, 5470, 5449, 11892, 2007, 1996, 2208, 1005, 1055, 4423, 3179, 2001, 2207, 1999, 2297, 1012, 2865, 1012, 4432, 2052, 2709, 2000, 1996, 6329, 2007, 1996, 2458, 1997, 11748, 4801, 4360, 1024, 24296, 4329, 2005, 1996, 9160, 1018, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(writer, model_file=None, data_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it really work? Is it really intelligent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `SentPairDataset` dataset object and the `DataLoader` data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPD = SentPairDataset('./data/wiki.test.tokens',\n",
    "                                16,\n",
    "                                tokenize,\n",
    "                                400,\n",
    "                                pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 109, in __getitem__\n    instance = proc(instance)\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 192, in __call__\n    assert len(input_) == max_len, f\"unexpected shape in {input_.__name__}: {input_}\"\nNameError: name 'max_len' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf4282711c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                        num_workers=8)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/anaconda3/envs/gr3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 109, in __getitem__\n    instance = proc(instance)\n  File \"/home/vinitrinh/Desktop/trainfromhome-transformer/src/data.py\", line 192, in __call__\n    assert len(input_) == max_len, f\"unexpected shape in {input_.__name__}: {input_}\"\nNameError: name 'max_len' is not defined\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "tokenizer = src.tokenization.FullTokenizer(vocab_file='./data/vocab.txt', do_lower_case=True)\n",
    "tokenize = lambda x: tokenizer.tokenize(tokenizer.convert_to_unicode(x))\n",
    "\n",
    "pipeline = [Preprocess4Pretrain(75,\n",
    "                                0.15,\n",
    "                                list(tokenizer.vocab.keys()),\n",
    "                                tokenizer.convert_tokens_to_ids,\n",
    "                                400,\n",
    "                                1,\n",
    "                                1,\n",
    "                                3)]\n",
    "data_iter = DataLoader(SentPairDataset('./data/wiki.test.tokens',\n",
    "                            16,\n",
    "                            tokenize,\n",
    "                            400,\n",
    "                            pipeline=pipeline\n",
    "                                      ), \n",
    "                       batch_size=16, \n",
    "                       collate_fn=seq_collate, \n",
    "                       num_workers=8)\n",
    "\n",
    "for batch in tqdm(data_iter):\n",
    "    input_ids, segment_ids, input_mask, masked_ids, masked_pos, masked_weights, is_next, original_ids = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
